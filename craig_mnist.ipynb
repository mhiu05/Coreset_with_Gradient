{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-11T11:45:22.501960Z",
     "start_time": "2025-08-11T11:45:22.497311Z"
    }
   },
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Input\n",
    "import numpy as np\n",
    "import time\n",
    "import util"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T11:33:18.461519Z",
     "start_time": "2025-08-11T11:33:18.133867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)"
   ],
   "id": "4786193dbcd1f3cd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T11:33:21.280296Z",
     "start_time": "2025-08-11T11:33:21.273186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_classes, smtk = 10, 0\n",
    "Y_train_nocat = Y_train\n",
    "Y_train = to_categorical(Y_train, num_classes)\n",
    "Y_test = to_categorical(Y_test, num_classes)"
   ],
   "id": "bb7d4aabe84d0956",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T11:33:22.932691Z",
     "start_time": "2025-08-11T11:33:22.925980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "# subset, random = False, False  # all\n",
    "subset, random = True, False  # greedy\n",
    "# subset, random = True, True  # random\n",
    "subset_size = .4 if subset else 1.0\n",
    "epochs = 15\n",
    "reg = 1e-4\n",
    "runs = 5\n",
    "save_subset = False\n",
    "\n",
    "folder = f'/tmp/mnist'"
   ],
   "id": "f8ea31389b166007",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T11:34:54.831993Z",
     "start_time": "2025-08-11T11:34:54.801305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(784,)),\n",
    "    Dense(100, activation='sigmoid', kernel_regularizer=l2(reg)),\n",
    "    Dense(10, activation='softmax', kernel_regularizer=l2(reg))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    optimizer='sgd'\n",
    ")"
   ],
   "id": "9c1a4b8a9a1556fa",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T11:35:13.745254Z",
     "start_time": "2025-08-11T11:35:13.739868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loss, test_loss = np.zeros((runs, epochs)), np.zeros((runs, epochs))\n",
    "train_acc, test_acc = np.zeros((runs, epochs)), np.zeros((runs, epochs))\n",
    "train_time = np.zeros((runs, epochs))\n",
    "grd_time, sim_time, pred_time = np.zeros((runs, epochs)), np.zeros((runs, epochs)), np.zeros((runs, epochs))\n",
    "not_selected = np.zeros((runs, epochs))\n",
    "times_selected = np.zeros((runs, len(X_train)))\n",
    "best_acc = 0\n",
    "print(f'----------- smtk: {smtk} ------------')"
   ],
   "id": "30ccc22d01523297",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- smtk: 0 ------------\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T11:35:29.006387Z",
     "start_time": "2025-08-11T11:35:29.001699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if save_subset:\n",
    "    B = int(subset_size * len(X_train))\n",
    "    selected_ndx = np.zeros((runs, epochs, B))\n",
    "    selected_wgt = np.zeros((runs, epochs, B))\n"
   ],
   "id": "ae0237f04aefa4c6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T11:45:46.267643Z",
     "start_time": "2025-08-11T11:45:26.754817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for run in range(runs):\n",
    "    X_subset = X_train\n",
    "    Y_subset = Y_train\n",
    "    W_subset = np.ones(len(X_subset))\n",
    "    ordering_time,similarity_time, pre_time = 0, 0, 0\n",
    "    loss_vec, acc_vec, time_vec = [], [], []\n",
    "    for epoch in range(0, epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        num_batches = int(np.ceil(X_subset.shape[0] / float(batch_size)))\n",
    "\n",
    "        for index in range(num_batches):\n",
    "            X_batch = X_subset[index * batch_size:(index + 1) * batch_size]\n",
    "            Y_batch = Y_subset[index * batch_size:(index + 1) * batch_size]\n",
    "            W_batch = W_subset[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "            start = time.time()\n",
    "            history = model.train_on_batch(X_batch, Y_batch, sample_weight=W_batch)\n",
    "            train_time[run][epoch] += time.time() - start\n",
    "\n",
    "        if subset:\n",
    "            if random:\n",
    "                # indices = np.random.randint(0, len(X_train), int(subset_size * len(X_train)))\n",
    "                indices = np.arange(0, len(X_train))\n",
    "                np.random.shuffle(indices)\n",
    "                indices = indices[:int(subset_size * len(X_train))]\n",
    "                W_subset = np.ones(len(indices))\n",
    "            else:\n",
    "                start = time.time()\n",
    "                _logits = model.predict(X_train)\n",
    "                pre_time = time.time() - start\n",
    "                features = _logits - Y_train\n",
    "\n",
    "                indices, W_subset, _, _, ordering_time, similarity_time = util.get_orders_and_weights(\n",
    "                    int(subset_size * len(X_train)), features, 'euclidean', smtk, 0, False, Y_train_nocat)\n",
    "\n",
    "                W_subset = W_subset / np.sum(W_subset) * len(W_subset)  # todo\n",
    "\n",
    "            if save_subset:\n",
    "                selected_ndx[run, epoch], selected_wgt[run, epoch] = indices, W_subset\n",
    "\n",
    "            grd_time[run, epoch], sim_time[run, epoch], pred_time[run, epoch] = ordering_time, similarity_time, pre_time\n",
    "            times_selected[run][indices] += 1\n",
    "            not_selected[run, epoch] = np.sum(times_selected[run] == 0) / len(times_selected[run]) * 100\n",
    "        else:\n",
    "            pred_time = 0\n",
    "            indices = np.arange(len(X_train))\n",
    "\n",
    "        X_subset = X_train[indices, :]\n",
    "        Y_subset = Y_train[indices]\n",
    "\n",
    "        start = time.time()\n",
    "        score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "        eval_time = time.time()-start\n",
    "\n",
    "        start = time.time()\n",
    "        score_loss = model.evaluate(X_train, Y_train, verbose=1)\n",
    "        print(f'eval time on training: {time.time()-start}')\n",
    "\n",
    "        test_loss[run][epoch], test_acc[run][epoch] = score[0], score[1]\n",
    "        train_loss[run][epoch], train_acc[run][epoch] = score_loss[0], score_loss[1]\n",
    "        best_acc = max(test_acc[run][epoch], best_acc)\n",
    "\n",
    "        grd = 'random_wor' if random else 'grd_normw'\n",
    "        print(f'run: {run}, {grd}, subset_size: {subset_size}, epoch: {epoch}, test_acc: {test_acc[run][epoch]}, '\n",
    "              f'loss: {train_loss[run][epoch]}, best_prec1_gb: {best_acc}, not selected %:{not_selected[run][epoch]}')\n",
    "\n",
    "    if save_subset:\n",
    "        print(\n",
    "            f'Saving the results to {folder}_{subset_size}_{grd}_{runs}')\n",
    "\n",
    "        np.savez(f'{folder}_{subset_size}_{grd}_{runs}',\n",
    "                 # f'_{grd}_{args.lr_schedule}_start_{args.start_subset}_lag_{args.lag}_subset',\n",
    "                 train_loss=train_loss, test_acc=test_acc, train_acc=train_acc, test_loss=test_loss,\n",
    "                 train_time=train_time, grd_time=grd_time, sim_time=sim_time, pred_time=pred_time,\n",
    "                 not_selected=not_selected, times_selected=times_selected,\n",
    "                 subset=selected_ndx, weights=selected_wgt)\n",
    "    else:\n",
    "        print(\n",
    "            f'Saving the results to {folder}_{subset_size}_{grd}_{runs}')\n",
    "\n",
    "        np.savez(f'{folder}_{subset_size}_{grd}_{runs}',\n",
    "                 # f'_{grd}_{args.lr_schedule}_start_{args.start_subset}_lag_{args.lag}',\n",
    "                 train_loss=train_loss, test_acc=test_acc, train_acc=train_acc, test_loss=test_loss,\n",
    "                 train_time=train_time, grd_time=grd_time, sim_time=sim_time, pred_time=pred_time,\n",
    "                 not_selected=not_selected, times_selected=times_selected)"
   ],
   "id": "cf00c03c4ac6b922",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 4ms/step\n",
      "not equal_num\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'faciliy_location_order' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[28]\u001B[39m\u001B[32m, line 33\u001B[39m\n\u001B[32m     30\u001B[39m     pre_time = time.time() - start\n\u001B[32m     31\u001B[39m     features = _logits - Y_train\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m     indices, W_subset, _, _, ordering_time, similarity_time = \u001B[43mutil\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_orders_and_weights\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     34\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubset_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43meuclidean\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msmtk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train_nocat\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     36\u001B[39m     W_subset = W_subset / np.sum(W_subset) * \u001B[38;5;28mlen\u001B[39m(W_subset)  \u001B[38;5;66;03m# todo\u001B[39;00m\n\u001B[32m     38\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m save_subset:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\util.py:64\u001B[39m, in \u001B[36mget_orders_and_weights\u001B[39m\u001B[34m(B, X, metric, smtk, no, stoch_greedy, y, weights, equal_num, outdir)\u001B[39m\n\u001B[32m     51\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mnot equal_num\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     53\u001B[39m \u001B[38;5;66;03m# print(f'Greedy: selecting {num_per_class} elements')\u001B[39;00m\n\u001B[32m     54\u001B[39m \n\u001B[32m     55\u001B[39m \u001B[38;5;66;03m# order_mg_all = np.zeros([C, num_per_class], dtype=np.int64)\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     62\u001B[39m \u001B[38;5;66;03m#     lambda c: faciliy_location_order(c, X, y, metric, num_per_class[c], smtk, stoch_greedy, weights), classes))\u001B[39;00m\n\u001B[32m     63\u001B[39m \u001B[38;5;66;03m# pool.terminate()\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m64\u001B[39m order_mg_all, cluster_sizes_all, greedy_times, similarity_times = \u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m     65\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfaciliy_location_order\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_per_class\u001B[49m\u001B[43m[\u001B[49m\u001B[43mc\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msmtk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mno\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstoch_greedy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclasses\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     67\u001B[39m order_mg, weights_mg = [], []\n\u001B[32m     68\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m equal_num:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\util.py:65\u001B[39m, in \u001B[36mget_orders_and_weights.<locals>.<lambda>\u001B[39m\u001B[34m(c)\u001B[39m\n\u001B[32m     51\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mnot equal_num\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     53\u001B[39m \u001B[38;5;66;03m# print(f'Greedy: selecting {num_per_class} elements')\u001B[39;00m\n\u001B[32m     54\u001B[39m \n\u001B[32m     55\u001B[39m \u001B[38;5;66;03m# order_mg_all = np.zeros([C, num_per_class], dtype=np.int64)\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     62\u001B[39m \u001B[38;5;66;03m#     lambda c: faciliy_location_order(c, X, y, metric, num_per_class[c], smtk, stoch_greedy, weights), classes))\u001B[39;00m\n\u001B[32m     63\u001B[39m \u001B[38;5;66;03m# pool.terminate()\u001B[39;00m\n\u001B[32m     64\u001B[39m order_mg_all, cluster_sizes_all, greedy_times, similarity_times = \u001B[38;5;28mzip\u001B[39m(*\u001B[38;5;28mmap\u001B[39m(\n\u001B[32m---> \u001B[39m\u001B[32m65\u001B[39m     \u001B[38;5;28;01mlambda\u001B[39;00m c: \u001B[43mfaciliy_location_order\u001B[49m(c, X, y, metric, num_per_class[c], smtk, no, stoch_greedy, weights), classes))\n\u001B[32m     67\u001B[39m order_mg, weights_mg = [], []\n\u001B[32m     68\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m equal_num:\n",
      "\u001B[31mNameError\u001B[39m: name 'faciliy_location_order' is not defined"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
